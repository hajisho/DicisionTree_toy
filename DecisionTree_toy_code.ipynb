{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用するデータ\n",
    "\n",
    "天気 | 風速 | 湿度 || 花火 \\\n",
    "ーーーーーーーーーー\\\n",
    "晴れ | 強い | 高い || No\\\n",
    "曇り | 弱い | 高い || Yes\\\n",
    "曇り | 強い | 低い || No\\\n",
    "晴れ | 弱い | 高い || Yes\\\n",
    "雨　 | 弱い | 高い || No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name = ['天気','風速','湿度']\n",
    "labels = [['晴れ', '曇り', '曇り', '晴れ' , '雨' ],\n",
    "         ['強い', '弱い', '強い', '弱い' , '弱い'],\n",
    "        ['高い', '高い', '低い', '高い' , '高い']]\n",
    "target   = ['No' , 'Yes' , 'No' , 'Yes' , 'No' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ID3アルゴリズム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3():   \n",
    "    def get_entropy(self,target):\n",
    "        \"\"\"\n",
    "        エントロピーを求める。\n",
    "        入力\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "        出力\n",
    "           entropy：float。入力データに対するエントロピーを返す。\n",
    "\n",
    "        例)\n",
    "           target  = ['No','Yes','No','Yes','No']\n",
    "           =>2/5*log2(5/2) + 3/5*log2(5/3) = 0.972\n",
    "        \"\"\"\n",
    "        classes = set(target)\n",
    "        class_num = len(classes)\n",
    "        element_num = len(target)\n",
    "        entropy = 0\n",
    "        for i in classes:\n",
    "            i_num = np.count_nonzero(target==i)\n",
    "            p_i = i_num/element_num\n",
    "            entropy -= p_i * math.log2(p_i)\n",
    "        return entropy\n",
    "    \n",
    "    def get_information_gain(self,label, target):\n",
    "        \"\"\"\n",
    "        labelで分類した場合の、エントロピーを求める\n",
    "        入力\n",
    "            label ：1次元のndarray。各データの属性値を並べたもの\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "        出力\n",
    "           entropy：float。入力データに対する情報ゲインを返す。\n",
    "\n",
    "        例)\n",
    "           label  = ['晴れ', '曇り','曇り','晴れ' ,'雨'] \n",
    "           target = ['No' , 'Yes' ,'No' ,'Yes' ,'No']\n",
    "           =>0.972 - 0.8 = 0.172\n",
    "\n",
    "        \"\"\"\n",
    "        origin_entropy = self.get_entropy(target)\n",
    "        labels = set(label)\n",
    "        element_num = len(target)\n",
    "        entropy = 0.\n",
    "        for i in labels:\n",
    "            i_index = [j for j, x in enumerate(label) if x == i]#該当ラベルのデータのindexのリスト\n",
    "            p_i = len(i_index)/element_num\n",
    "            label_i = label[i_index]\n",
    "            target_i = target[i_index]\n",
    "            entropy += p_i * self.get_entropy(target_i)\n",
    "        return origin_entropy - entropy\n",
    "    \n",
    "    def select_column(self,labels, target):\n",
    "        \"\"\"\n",
    "        情報ゲインが最大のラベルを求める\n",
    "        入力\n",
    "            label ：ndarray。各データの属性値を並べたもの\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "        出力\n",
    "           entropy：int。情報ゲイン(識別力)の最も高いラベルのindexを返す\n",
    "\n",
    "        例)\n",
    "           label[0] = ['晴れ', '曇り', '曇り', '晴れ' , '雨' ] : 天気\n",
    "           label[1] = ['強い', '弱い', '強い', '弱い' , '弱い'] :風速\n",
    "           label[2] = ['高い', '高い', '低い', '高い' , '高い'] :湿度\n",
    "           target   = ['No' , 'Yes' , 'No' , 'Yes' , 'No' ]\n",
    "           =>情報gainは、 0.172, 0.423, 0.172となり、\n",
    "\n",
    "        注)　各ラベルで分類前のエントロピーは一定のため、\n",
    "           実際には、各ラベルで分類後のエントロピーが最大のものを選んだ方が、計算コストは低い\n",
    "        \"\"\"\n",
    "        gains = list()\n",
    "        for i in labels:\n",
    "            gains.append(self.get_information_gain(i,target))\n",
    "        gains = np.array(gains)\n",
    "        max_index = np.argmax(gains)\n",
    "        return max_index    \n",
    "    \n",
    "    def decision_tree(self, labels, target,labels_name,depth=1):\n",
    "        \"\"\"\n",
    "        ID3アルゴリズムによる決定木を出力する。\n",
    "        再起的に実行する\n",
    "        入力\n",
    "            labels ：ndarray。各データの属性値を並べたもの\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "            labels_nane：labelsにおける、各属性の名前\n",
    "            depth：int。木の深さ。※表示のインデントをつけるため\n",
    "        出力\n",
    "           -\n",
    "\n",
    "        \"\"\"\n",
    "        next_index = self.select_column(labels,target)#分類に使用する属性を決める\n",
    "        print(\"　\"*depth,'#',labels_name[next_index])\n",
    "        elems = set(labels[next_index])\n",
    "        for i in elems:\n",
    "            i_index = [j for j, x in enumerate(labels[next_index]) if x == i]#該当ラベルのデータのindexのリスト\n",
    "            label_i = labels[:,i_index]\n",
    "            target_i = target[i_index]\n",
    "            if np.all(target_i == target_i[0]):\n",
    "                class_name = target_i[0]\n",
    "                print(\"　\"*(depth+1),'-',i,':',class_name)\n",
    "                continue\n",
    "            print(\"　\"*(depth+1),'-',i,)\n",
    "            self.decision_tree(label_i,target_i,labels_name, depth+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decision_tree_by_ID3(labels_name,labels, target):\n",
    "    \"\"\"\n",
    "    ID3アルゴリズムによる決定木を表示する\n",
    "     入力\n",
    "        labels ：list。各データの属性値を並べたもの\n",
    "        target：list。各データのクラスを並べたもの\n",
    "        labels_nane：list。labelsにおける、各属性の名前\n",
    "    \"\"\"\n",
    "    labels_name = np.array(labels_name)\n",
    "    labels = np.array(labels)\n",
    "    target = np.array(target)\n",
    "    \n",
    "    model = ID3()\n",
    "    \n",
    "    model.decision_tree(labels,target,labels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "　 # 風速\n",
      "　　 - 弱い\n",
      "　　　 # 天気\n",
      "　　　　 - 曇り : Yes\n",
      "　　　　 - 雨 : No\n",
      "　　　　 - 晴れ : Yes\n",
      "　　 - 強い : No\n"
     ]
    }
   ],
   "source": [
    "print_decision_tree_by_ID3(labels_name,labels,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 出力について\n",
    "出力結果は、\n",
    "- \\#がクラス\n",
    "- \\-が属性値を表す\n",
    "\n",
    "インデントで、木の深さを表している\n",
    "\n",
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARTアルゴリズム"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CART():\n",
    "    def get_gini_impurity(self,target):\n",
    "        \"\"\"\n",
    "        ジニ不純度を求める。\n",
    "        入力\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "        出力\n",
    "           gini：float。入力データに対するジニ不純度を返す。\n",
    "\n",
    "        例)\n",
    "           target  = ['No','Yes','No','Yes','No']\n",
    "           => 2/5(1 - 2/5) + 3/5(1 - 3/5) = 0.48\n",
    "        \"\"\"\n",
    "        classes = set(target)\n",
    "        class_num = len(classes)\n",
    "        element_num = len(target)\n",
    "        gini = 0\n",
    "        for i in classes:\n",
    "            i_num = np.count_nonzero(target==i)\n",
    "            p_i = i_num/element_num\n",
    "            gini += p_i * (1 - p_i)\n",
    "        return gini\n",
    "    \n",
    "    def get_information_gain(self, label, atribute, target):\n",
    "        \"\"\"\n",
    "        labelで分類した場合の、エントロピーを求める\n",
    "        入力\n",
    "            label ：1次元のndarray。各データの属性値を並べたもの\n",
    "            atribute：string。情報ゲインを計算する属性値。\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "        出力\n",
    "           entropy：float。入力データに対する情報ゲインを返す。\n",
    "\n",
    "        例)\n",
    "           label  = ['晴れ', '曇り','曇り','晴れ' ,'雨']\n",
    "           atribute = '晴れ'\n",
    "           target = ['No' , 'Yes' ,'No' ,'Yes' ,'No']\n",
    "           => 0.48 - ( 2/5*0.5 + 3/5*0.44444) = 0.13333\n",
    "\n",
    "        \"\"\"\n",
    "        origin_gini = self.get_gini_impurity(target)\n",
    "        element_num = len(target)\n",
    "        gini = 0.\n",
    "        #属性値=atributeについて\n",
    "        i_index = [j for j, x in enumerate(label) if x == atribute]#該当ラベルのデータのindexのリスト\n",
    "        p_i = len(i_index)/element_num\n",
    "        label_i = label[i_index]\n",
    "        target_i = target[i_index]\n",
    "        gini += p_i * self.get_gini_impurity(target_i)\n",
    "        #その他について\n",
    "        i_index = [j for j, x in enumerate(label) if x != atribute]#該当ラベルのデータのindexのリスト\n",
    "        p_i = len(i_index)/element_num\n",
    "        label_i = label[i_index]\n",
    "        target_i = target[i_index]\n",
    "        gini += p_i * self.get_gini_impurity(target_i)\n",
    "        return origin_gini - gini\n",
    "    \n",
    "    def select_column(self, labels, target):\n",
    "        \"\"\"\n",
    "        情報ゲインが最大のラベルを求める\n",
    "        入力\n",
    "            labels ：ndarray。各データの属性値を並べたもの\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "        出力\n",
    "           index：int。情報ゲイン(識別力)の最も高いラベルのindex\n",
    "            atribute:str。情報ゲイン(識別力)の最も高い属性値を返す\n",
    "\n",
    "        例)\n",
    "           labels[0] = ['晴れ', '曇り', '曇り', '晴れ' , '雨' ] : 天気\n",
    "           labels[1] = ['強い', '弱い', '強い', '弱い' , '弱い'] :風速\n",
    "           labels[2] = ['高い', '高い', '低い', '高い' , '高い'] :湿度\n",
    "           target   = ['No' , 'Yes' , 'No' , 'Yes' , 'No' ]\n",
    "           =>情報gainは、 0.172, 0.423, 0.172となり、\n",
    "\n",
    "        注)　属性値が2種類の属性に対して、下記のコードは実際には冗長である。(どちらか1つについて情報ゲインを計算すれば本来良い)\n",
    "        \"\"\"\n",
    "        gains = list()\n",
    "        for i,l in enumerate(labels):\n",
    "            ls = list(set(l))#その属性における属性値のユニークなリスト\n",
    "            for j in ls:\n",
    "                gains.append([i,j,self.get_information_gain(l,j,target)])#[属性(labelsのindex), 属性値, 情報ゲイン]\n",
    "        gains = np.array(gains)\n",
    "        max_index = np.argmax(gains[:,2])\n",
    "        return int(gains[max_index,0]),gains[max_index,1]\n",
    "    \n",
    "    def decision_tree(self, labels, target,labels_name,depth=1):\n",
    "        \"\"\"\n",
    "        ID3アルゴリズムによる決定木を出力する。\n",
    "        再起的に実行する\n",
    "        入力\n",
    "            labels ：ndarray。各データの属性値を並べたもの\n",
    "            target：1次元のndarray。各データのクラスを並べたもの\n",
    "            labels_nane：labelsにおける、各属性の名前\n",
    "            depth：int。木の深さ。※表示のインデントをつけるため\n",
    "        出力\n",
    "           -\n",
    "\n",
    "        \"\"\"\n",
    "        next_index,atribute = self.select_column(labels,target)#分類に使用する属性を決める\n",
    "        print(\"　\"*depth,'#',labels_name[next_index])\n",
    "        #今回分類に使用する属性値のデータについて\n",
    "        i_index = [j for j, x in enumerate(labels[next_index]) if x == atribute]#該当ラベルのデータのindexのリスト\n",
    "        label_i = labels[:,i_index]\n",
    "        target_i = target[i_index]\n",
    "        if np.all(target_i == target_i[0]):\n",
    "            class_name = target_i[0]\n",
    "            print(\"　\"*(depth+1),'-',atribute,':',class_name)\n",
    "        else:\n",
    "            print(\"　\"*(depth+1),'-',atribute,)\n",
    "            self.decision_tree(label_i,target_i,labels_name, depth+2)\n",
    "\n",
    "        #それ以外のデータについて\n",
    "        i_index = [j for j, x in enumerate(labels[next_index]) if x != atribute]#該当ラベルのデータのindexのリスト\n",
    "        label_i = labels[:,i_index]\n",
    "        target_i = target[i_index]\n",
    "        if np.all(target_i == target_i[0]):\n",
    "            class_name = target_i[0]\n",
    "            print(\"　\"*(depth+1),'-','NOT'+atribute,':',class_name)\n",
    "        else:\n",
    "            print(\"　\"*(depth+1),'-','NOT'+atribute,)\n",
    "            self.decision_tree(label_i,target_i,labels_name, depth+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_decision_tree_by_CART(labels_name,labels, target):\n",
    "    \"\"\"\n",
    "    ID3アルゴリズムによる決定木を表示する\n",
    "     入力\n",
    "        labels ：list。各データの属性値を並べたもの\n",
    "        target：list。各データのクラスを並べたもの\n",
    "        labels_nane：list。labelsにおける、各属性の名前\n",
    "    \"\"\"\n",
    "    labels_name = np.array(labels_name)\n",
    "    labels = np.array(labels)\n",
    "    target = np.array(target)\n",
    "    \n",
    "    model = CART()\n",
    "    \n",
    "    model.decision_tree(labels,target,labels_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "　 # 風速\n",
      "　　 - 弱い\n",
      "　　　 # 天気\n",
      "　　　　 - 雨 : No\n",
      "　　　　 - NOT雨 : Yes\n",
      "　　 - NOT弱い : No\n"
     ]
    }
   ],
   "source": [
    "print_decision_tree_by_CART(labels_name,labels,target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
